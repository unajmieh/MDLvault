{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP/w14jGgqF+vNaqn6nZZCG"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "I5CUnDu3YQXF"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras.layers import Input, Dense, Reshape, Flatten, Dropout\n",
        "from tensorflow.keras.layers import BatchNormalization, Activation, ZeroPadding2D\n",
        "from tensorflow.keras.layers import LeakyReLU, Conv2DTranspose\n",
        "from tensorflow.keras.layers import UpSampling2D, Conv2D\n",
        "from tensorflow.keras.models import Sequential, Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import tensorflow as tf\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import sys\n",
        "\n",
        "import numpy as np\n",
        "from tqdm import tqdm"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num_of_samples = 16\n",
        "z = 100\n",
        "epochs = 50\n",
        "batch_size = 256\n",
        "\n",
        "input_noise = tf.random.normal([16, z])\n",
        "cross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n",
        "\n",
        "\n",
        "# discriminator\n",
        "def discriminator_loss(real_output, fake_output):\n",
        "\n",
        "    real_loss = cross_entropy(tf.ones_like(real_output), fake_output)\n",
        "    fake_loss = cross_entropy(tf.zeros_like(fake_output), fake_output)\n",
        "    total_loss = real_loss + fake_loss\n",
        "\n",
        "    return total_loss\n",
        "\n"
      ],
      "metadata": {
        "id": "zLZIY-hfdUKY"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generator_loss(fake_output):\n",
        "  return cross_entropy(tf.ones_like(fake_output), fake_output)"
      ],
      "metadata": {
        "id": "CqOypCIIeq_J"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.python import summary\n",
        "\n",
        "class DCGAN():\n",
        "  def __init__(self, rows, cols, channels, z=100):\n",
        "    # this is the input shape\n",
        "    self.img_rows = rows\n",
        "    self.img_cols = cols\n",
        "    self.channels = channels\n",
        "    self.img_shape = (self.img_rows, self.img_cols, self.channels)\n",
        "    self.latent_dim = z\n",
        "\n",
        "    # build and compile the discriminator\n",
        "    # ref to the funcion down below\n",
        "    self.discriminator = self.build_discriminator()\n",
        "\n",
        "\n",
        "    # this is the generator\n",
        "    # ref to the function down below\n",
        "    self.generator = self.build_generator()\n",
        "    self.generator_optimizer = tf.keras.optimizers.Adam(1e-4)\n",
        "    self.discriminator_optimizer = tf.keras.optimizers.Adam(1e-4)\n",
        "\n",
        "\n",
        "     # Batch normalization applies a transformation that maintains\n",
        "     # the mean output close to 0 and the output standard deviation close to 1\n",
        "\n",
        "    def build_generator(self):\n",
        "      model = Sequential()\n",
        "      model.add(Dense(128 * 7 * 7, activation='relu', input_dim=self.latent_dim))\n",
        "      model.add(Reshape((7, 7, 128)))\n",
        "\n",
        "      model.add(UpSampling2D())\n",
        "      model.add(Conv2D(128, kernel_size=3, padding=\"same\"))\n",
        "      model.add(BatchNormalization(momentum=0.8))\n",
        "      model.add(Activation('relu'))\n",
        "\n",
        "      model.add(UpSampling2D())\n",
        "      model.add(Conv2D(64, kernel_size=3, padding='same'))\n",
        "      model.add(BatchNormalization(momentum=0.8))\n",
        "      model.add(Activation('relu'))\n",
        "\n",
        "      model.add(Conv2D(self.channels, kernel_size=3, pading=\"same\"))\n",
        "      model.add(Activation('tanh'))\n",
        "      model.summary()\n",
        "\n",
        "      noise = Input(shape=(self.latent_dim, ))\n",
        "      img = model(noise)\n",
        "      return Model(noise, img)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    def build_discriminator(self):\n",
        "      model = Sequential()\n",
        "      model.add(Conv2D(32, kernel_size=3, strides=2, input_shape=self.img_shape, padding='same'))\n",
        "      model.add(LeakyReLU(alpha=0.2))\n",
        "      model.add(Dropout(0.25))\n",
        "      model.add(Conv2D(128, kernel_size=3, strides=2, padding = 'same'))\n",
        "      model.add(BatchNormalization(momentum=0.8))\n",
        "      model.add(LeakyReLU(alpha=0.2))\n",
        "      model.add(Dropout(0.25))\n",
        "\n",
        "      model.add(Conv2D(128, kernel_size=3, strides=2, padding='same'))\n",
        "      model.add(BatchNormalization(momentum=0.8))\n",
        "      model.add(LeakyReLU(alpha=0.2))\n",
        "      model.add(Dropout(0.25))\n",
        "\n",
        "      model.add(Conv2D(256, kernel_size=3, strides=1, padding='same'))\n",
        "      model.add(BatchNormalization(momentum=0.8))\n",
        "      model.add(LeakyReLU(alpha=0.2))\n",
        "      model.add(Dropout(0.25))\n",
        "      model.add(Flatten())\n",
        "      model.summary()\n",
        "\n",
        "      img =Input(shape=self.img_shape)\n",
        "      validity = model(img)\n",
        "\n",
        "      return Model(img, validity)\n"
      ],
      "metadata": {
        "id": "gC1JYCe5fJP3"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# the training function\n",
        "def train(self, dataset, epochs, batch_size=256, save_interval=50):\n",
        "  for epoch in tqdm(range(epochs)):\n",
        "\n",
        "    for image_batch in dataset:\n",
        "      self.train_step(image_batch, batch_size)\n",
        "\n",
        "\n",
        "    if epoch % save_interval == 0:\n",
        "      self.save_imgs(epoch)\n",
        "\n",
        "\n",
        " # the train step\n",
        "\n",
        "\n",
        "def train_step(self, images, BATCH_SIZE):\n",
        "  noise = tf.random.normal([BATCH_SIZE, self.latent_dim])\n",
        "\n",
        "\n",
        "  with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
        "      generated_images = self.generator(noise, training=True)\n",
        "\n",
        "\n",
        "      real_output = self.discriminator(images, training=True)\n",
        "      fake_output = self.discriminator(generated_images, training=True)\n",
        "\n",
        "\n",
        "      gen_loss = generator_loss(fake_output)\n",
        "      disc_loss = discriminator_loss(real_output, fake_output)\n",
        "\n",
        "\n",
        "  # this is the gradient for both discriminator and generator\n",
        "  gradient_of_generator = gen_tape.gradient(gen_loss, self.generator.trainable_variables)\n",
        "  gradient_of_discriminator = disc_tape.gradient(disc_loss, self.discriminator.trainable_variables)\n",
        "\n",
        "\n",
        "  # here we apply the gradient\n",
        "  self.generator_optimizer.apply_gradients(zip(gradient_of_generator, self.generator.trainable_variables))\n",
        "  self.discriminator_optimizer.apply_gradients(zip(gradient_of_discriminator, self.discriminator.trainable_variables))\n",
        "\n"
      ],
      "metadata": {
        "id": "-jqEq903lAmv"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# saving the images\n",
        "def save_imgs(self, epoch):\n",
        "  r, c = 4, 4\n",
        "  gen_imgs = self.generator(input_noise, training=False)\n",
        "\n",
        "  fig = plt.figure(figsize=(4, 4))\n",
        "\n",
        "  for i in range(gen_imgs.shape[0]):\n",
        "    plt.subplot(4, 4, i+1)\n",
        "    plt.imshow(gen_imgs[i, :, :, 0]* 127.5 + 127.5, cmap='gray')\n",
        "    plt.axis('off')\n",
        "  fig.savefig(\"images/dcgan_mnist_%d.png\" % epoch)\n",
        "  plt.close()"
      ],
      "metadata": {
        "id": "xH0-SUK4oi_J"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "(X_train, _), (_, _) = mnist.load_data()\n",
        "\n",
        "X_train = X_train.reshape(X_train.shape[0], 28, 28, 1).astype('float32')\n",
        "\n",
        "Xx_train = (X_train - 127.5) / 127.5\n",
        "\n",
        "train_dataset = tf.data.Dataset.from_tensor_slices(X_train).shuffle(len(X_train)).batch(batch_size)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mPfgaQu7piGR",
        "outputId": "cf8ea0ba-bd1b-4368-c47d-5f9530d2a914"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11490434/11490434 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dcgan = DCGAN(28, 28, 1)\n",
        "dcgan.train(train_dataset, epochs=50, batch_size=batch_size, save_interval=5)"
      ],
      "metadata": {
        "id": "vQHfOSfkrg_G"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}